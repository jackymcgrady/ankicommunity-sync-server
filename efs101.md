# EFS 101: Complete Guide for Anki Sync Server

## What is EFS?

**Amazon Elastic File System (EFS)** is like a magical shared hard drive that lives in the cloud. Think of it as a USB drive that multiple computers can use at the same time, except it:
- Never runs out of space (grows automatically)
- Can be accessed by multiple containers simultaneously
- Survives when containers restart or crash
- Works across different AWS availability zones

## Why Do We Need EFS for Anki Sync?

### The Problem with Local Storage
Before EFS, your Anki collections were stored like this:
```
EC2 Instance (your server)
└── /home/ec2-user/ankicommunity-sync-server/data/
    └── collections/
        └── users/
            └── huyuping/
                ├── collection.anki2         ← Your Anki cards
                ├── collection.anki2-wal     ← Database changes
                └── collection.media.server.db ← Media files info
```

**Problems**:
- ❌ If EC2 instance dies, all collections are lost
- ❌ Fargate containers can't access this local storage
- ❌ Can't scale to multiple containers
- ❌ No automatic backups

### The Solution with EFS
With EFS, your collections live in shared cloud storage:
```
EFS Filesystem (fs-04fc7861693cc007c)
└── collections/
    └── users/
        └── huyuping/
            ├── collection.anki2         ← Safe in the cloud
            ├── collection.anki2-wal     ← Accessible everywhere
            └── collection.media.server.db ← Never lost
```

**Benefits**:
- ✅ Survives container/server crashes
- ✅ Multiple containers can access simultaneously
- ✅ Automatic scaling and backups
- ✅ Works with Fargate, EC2, Lambda, etc.

## How Data Flows Through the System

### 1. User Syncs from Anki Client
```
[Anki Desktop/Mobile] 
    ↓ HTTPS Request
[nginx Proxy Container] 
    ↓ Internal HTTP
[Sync Server Container]
    ↓ File I/O
[EFS Mount at /data]
    ↓ Network File System (NFS)
[EFS Filesystem in AWS]
```

### 2. What Happens When You Sync

**Step 1: Authentication**
- User enters credentials in Anki
- Sync server validates with AWS Cognito
- Username determines storage path: `/data/collections/users/{username}/`

**Step 2: Collection Transfer**
- Anki client sends collection.anki2 (your cards, reviews, settings)
- Sync server writes to EFS: `/data/collections/users/huyuping/collection.anki2`
- EFS automatically saves across multiple AWS data centers

**Step 3: Media Sync**
- Anki client sends images, audio, video files
- Server processes and stores media metadata
- Files referenced in `collection.media.server.db` on EFS

### 3. How Multiple Containers Access Data

```
Container 1 (Fargate)     Container 2 (EC2)     Container 3 (Fargate)
      │                         │                       │
      └─────────────────────────┼───────────────────────┘
                                │
                          [EFS Mount]
                                │
                    [EFS Filesystem fs-04fc7861693cc007c]
                                │
                    /collections/users/huyuping/
                    ├── collection.anki2
                    ├── collection.anki2-wal  
                    └── collection.media.server.db
```

## Technical Deep Dive

### EFS Mount Process
When you ran:
```bash
sudo mount -t efs -o tls fs-04fc7861693cc007c:/ efs
```

Here's what happened:
1. **DNS Resolution**: Your EC2 looks up `fs-04fc7861693cc007c.efs.ap-southeast-1.amazonaws.com`
2. **Mount Target Discovery**: Finds the closest EFS mount target in your VPC
3. **TLS Connection**: Establishes encrypted connection to EFS
4. **NFS Mount**: Mounts the filesystem at `./efs/` directory

### File System Layout
```
./efs/                          ← EFS mount point on EC2
└── collections/                ← Root collections directory
    └── users/                  ← User separation directory
        └── {cognito_username}/ ← Individual user folders
            ├── collection.anki2     ← SQLite database (cards, decks, reviews)
            ├── collection.anki2-wal ← Write-Ahead Log (pending changes)
            └── collection.media.server.db ← Media file index
```

### Docker Container Integration
Your `docker-compose.latest.yml` maps EFS into the container:
```yaml
volumes:
  - ./efs:/data:rw  # EFS mount becomes /data inside container
```

Inside the container:
- App code reads/writes to `/data/collections/users/{username}/`
- This actually reads/writes to EFS filesystem
- Changes are immediately visible to other containers

## Data Storage Details

### Collection.anki2 File
- **Format**: SQLite database
- **Contents**: Cards, decks, reviews, study statistics, settings
- **Size**: Typically 1-50 MB per user
- **Updates**: Every sync writes new version + WAL file

### Collection.anki2-wal File
- **Purpose**: Write-Ahead Log for SQLite
- **Contents**: Pending database changes not yet committed
- **Behavior**: Created during writes, merged back to main DB
- **Size**: Usually small (KB to few MB)

### Collection.media.server.db
- **Purpose**: Tracks media files (images, audio, video)
- **Contents**: File hashes, names, sync status
- **Size**: Small database, grows with media collection

### How Files Are Accessed

1. **Read Operations** (User opens Anki):
   ```
   Anki Client → Sync Server → EFS Read → Return data
   ```

2. **Write Operations** (User syncs changes):
   ```
   Anki Client → Sync Server → EFS Write → Confirmation
   ```

3. **Concurrent Access** (Multiple users):
   ```
   User A → Container 1 → EFS:/users/userA/
   User B → Container 2 → EFS:/users/userB/
   User C → Container 1 → EFS:/users/userC/
   ```

## Performance and Reliability

### EFS Performance Characteristics
- **Throughput**: Scales with file system size (larger = faster)
- **Latency**: ~1-3ms for small operations
- **Consistency**: Strong consistency across all mount points
- **Durability**: 99.999999999% (11 9's) durability

### How This Affects Anki Sync
- **Sync Speed**: Typically 2-10 seconds for normal collections
- **Large Collections**: May take 30-60 seconds for 100MB+ collections
- **Media Sync**: Depends on image/audio file sizes
- **Multiple Users**: No performance impact (isolated file access)

## Troubleshooting Common Issues

### EFS Mount Fails
```bash
# Check if EFS utils are installed
rpm -qa | grep amazon-efs-utils

# Verify AWS credentials
aws sts get-caller-identity

# Check mount target accessibility
nslookup fs-04fc7861693cc007c.efs.ap-southeast-1.amazonaws.com
```

### Permission Issues
```bash
# Fix EFS ownership
sudo chown -R 1000:1000 efs/

# Check container can access files
docker exec anki-sync-server-nginx ls -la /data/collections/
```

### Container Can't Write to EFS
```bash
# Verify mount inside container
docker exec anki-sync-server-nginx df -h /data

# Check EFS mount options
mount | grep efs
```

### Collection Not Found
```bash
# Verify directory structure
ls -la efs/collections/users/

# Check for correct username path
docker logs anki-sync-server-nginx | grep "collection path"
```

## Migration Checklist

When moving from local storage to EFS:

### ✅ Pre-Migration
- [ ] Create EFS filesystem
- [ ] Install amazon-efs-utils
- [ ] Configure AWS credentials
- [ ] Stop Docker containers

### ✅ Migration Steps
- [ ] Mount EFS filesystem
- [ ] Copy existing collections to EFS
- [ ] Update docker-compose.yml volume mounts
- [ ] Fix file permissions (chown 1000:1000)
- [ ] Update container startup commands

### ✅ Post-Migration
- [ ] Start containers with EFS mount
- [ ] Verify collections accessible from container
- [ ] Test user sync functionality
- [ ] Monitor container logs for errors

## Security Considerations

### Encryption
- **In Transit**: TLS encryption when mounting with `-o tls`
- **At Rest**: EFS encrypts data automatically
- **Network**: Traffic between container and EFS is encrypted

### Access Control
- **IAM Permissions**: Control who can mount/access EFS
- **VPC Security Groups**: Limit network access to EFS mount targets
- **File Permissions**: Standard Unix permissions (1000:1000 for anki user)

### Backup and Recovery
- **Automatic Backups**: EFS can be configured for automatic backups
- **Point-in-Time**: Restore to specific timestamps
- **Cross-Region**: Replicate to other AWS regions for disaster recovery

## Cost Optimization

### EFS Pricing Factors
- **Storage Used**: Pay only for data stored ($0.30/GB/month)
- **Throughput**: Optional provisioned throughput costs
- **Requests**: Minimal cost per file operation

### Anki Collection Costs
- **Typical User**: 10-50 MB = $0.003-0.015/month
- **Heavy User**: 500 MB = $0.15/month
- **Media Heavy**: 2 GB = $0.60/month

### Cost Optimization Tips
- Use EFS Infrequent Access for old collections
- Enable EFS Intelligent Tiering
- Monitor usage with CloudWatch metrics

## Next Steps

Now that you understand EFS with your Anki sync server:

1. **Monitor Performance**: Set up CloudWatch metrics for EFS
2. **Implement Backups**: Configure EFS backup policies
3. **Scale to Fargate**: Use same EFS mount in Fargate task definitions
4. **Add Monitoring**: Track sync performance and error rates
5. **Disaster Recovery**: Set up cross-region EFS replication

## Conclusion

EFS transforms your Anki sync server from a single-server solution to a scalable, resilient cloud service. Your user collections are now:
- ✅ **Safe**: Protected across multiple AWS data centers
- ✅ **Scalable**: Accessible by unlimited containers
- ✅ **Fast**: Low-latency access for sync operations
- ✅ **Reliable**: 99.999999999% durability guarantee

Your users can sync from anywhere, anytime, knowing their study progress is securely stored in the cloud and accessible from any device.