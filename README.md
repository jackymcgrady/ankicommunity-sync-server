# Anki Sync Server

A production-ready, self-hosted implementation of Anki's sync protocol with AWS Cognito authentication and HTTPS support.  
If you manage multiple Anki clients (desktop, mobile, web) and need a **secure alternative** to AnkiWeb, this server keeps every device in perfect syncâ€”collections, media, and review history included.

## âœ… Production Status

**BATTLE-TESTED FEATURES:**
- âœ… **Robust collection sync** with intelligent conflict resolution and database integrity protection
- âœ… **HTTPS connectivity** with automatic SSL certificates via nginx reverse proxy
- âœ… **AWS Cognito authentication** with secure username-based collection isolation
- âœ… **Efficient media sync** - differential sync handles thousands of files with minimal data transfer
- âœ… **Modern Anki client compatibility** (v25.02+) with full protocol compliance
- âœ… **Docker deployment** with production-grade nginx SSL termination and monitoring
- âœ… **Crash recovery** - media databases survive server restarts, collections auto-restore from uploads

## ðŸš€ Quick Start

### Production Deployment (nginx + Let's Encrypt)
```bash
# 1. Configure environment variables for security
cp .env.example .env
# Edit .env with your AWS credentials and Cognito settings

# 2. Deploy with secure environment variables
docker-compose -f docker-compose.latest.yml up -d

# 3. Verify services are running
docker-compose -f docker-compose.latest.yml ps

# 4. Users authenticate via Cognito - no manual user creation needed
# Connect Anki to: https://your-domain.com
```

### âš ï¸ SECURITY SETUP REQUIRED
**CRITICAL**: Never commit AWS credentials to git. Use environment variables:
```bash
# Required environment variables (set in .env file):
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
ANKISYNCD_COGNITO_USER_POOL_ID=your_user_pool_id
ANKISYNCD_COGNITO_CLIENT_ID=your_client_id
ANKISYNCD_COGNITO_CLIENT_SECRET=your_client_secret
DOMAIN_NAME=your-domain.com
EMAIL=your-email@example.com
```

### Local Development
```bash
# Clone and configure
git clone https://github.com/your-username/ankicommunity-sync-server.git
cd ankicommunity-sync-server

# Setup environment variables
cp .env.example .env
# Edit .env with your credentials

# Start with secure configuration
docker-compose -f docker-compose.latest.yml up -d

# Connect Anki to: https://your-domain.com
```

---

## The User Story
1. **Edit Anywhere** â€“ Study on your phone during the commute, then refine cards on your laptop at night.
2. **Hit *Sync*** â€“ Each client contacts the same endpoint (`/sync`) over HTTPS and authenticates with your credentials.
3. **See Magic** â€“ The server reconciles review logs, note edits, card scheduling, and media additions so every device looks identical the next time you open Anki.

Behind that *Sync* button lives a carefully orchestrated sequence of database merges, conflict resolution, and media transfersâ€”performed safely, atomically, and as fast as possible.

---

## Architecture at a Glance
â€¢ **Protocol Compatibility** â€“ Implements the exact RPC contract used by official Anki 2.1.57+, including media-sync sub-protocol (`/msync`).  
â€¢ **SQLite-First Storage** â€“ Each profile stores its `collection.anki2` plus companion media databases on the server.  
â€¢ **Write-Ahead Logging (WAL)** â€“ Concurrency-friendly mode lets the server serve parallel read/write transactions without blocking.  
â€¢ **Batch Streaming** â€“ Large payloadsâ€”card revlogs, media blobsâ€”stream in configurable chunks to minimize memory pressure.  
â€¢ **Pythonic Core** â€“ Pure-Python implementation (3.9+) with minimal external deps; easy to read, extend, and debug.

---

## Core Components
| Module | Responsibility |
| ------ | -------------- |
| `sync_app.py` & `server.py` | ASGI/WSGI entry points; route RPC calls to handlers |
| `sync.py` | High-level orchestration of the sync transaction |
| `collection/` | SQLite collection wrapper with schema upgrades |
| `media_manager.py` | Deduplicates, normalizes, and streams media files |
| `users/cognito_manager.py` | **AWS Cognito authentication** with username-based collections |

Each component is **loosely coupled** for easy customization and monitoring integration.

---

## Sync Workflow (Incremental)
1. **Handshake** â€“ Client sends local `mod` and `usn`; server decides if fast-forward, merge, or full-sync is needed.
2. **Graves & Revs** â€“ Deleted objects and review logs arrive first, applied in isolated transactions.
3. **Chunked Changes** â€“ New/updated notes, cards, decks, etc., stream in batched JSON.
4. **Media Inventory** â€“ Separate `/msync` endpoint exchanges file hashes and pushes/pulls missing media.
5. **Finish & Ack** â€“ Server returns new `usn` and updated deck config so the client can update scheduling.

All steps run inside a **single WAL-protected transaction**; on any error the database rolls back to a pre-sync snapshot.

---

## Data Integrity & Safety
* **Checksum validation** on every received collection file and media chunk.
* **Automatic schema migrations** keep legacy clients functional across versions 11-18.
* **Conflict resolution** follows upstream Anki logic (newer `mod` wins, deterministic tie-breakers).
* **Locked writes** ensure two devices never overwrite each other's work mid-sync.
* **Crash resilience** - separated storage for collections and media enables recovery from server failures.
* **Differential media sync** - only transfers changed files using USN tracking, not full collections.
* **Modern media USN handling** - unified media manager ensures precise USN tracking that matches client expectations.
* **Schema compatibility** - robust fallback mechanisms handle corrupted or missing collection databases.

---

## Configuration

### âš ï¸ Security-First Configuration
**CRITICAL**: Use `.env` file for all credentials. Never commit secrets to git.

### Required Environment Variables
Copy `.env.example` to `.env` and configure:

| Environment Variable | Purpose | Required |
| ------------------- | ------- | -------- |
| `AWS_ACCESS_KEY_ID` | AWS access key | âœ… Required |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key | âœ… Required |
| `ANKISYNCD_COGNITO_USER_POOL_ID` | Cognito User Pool ID | âœ… Required |
| `ANKISYNCD_COGNITO_CLIENT_ID` | Cognito App client ID | âœ… Required |
| `ANKISYNCD_COGNITO_CLIENT_SECRET` | Cognito client secret | âœ… Required |
| `ANKISYNCD_COGNITO_REGION` | AWS region | âœ… Required |
| `DOMAIN_NAME` | Your domain for SSL certificates | âœ… Required |
| `EMAIL` | Email for Let's Encrypt | âœ… Required |

### Optional Configuration
| Env Var | Purpose | Default |
| ------- | ------- | ------- |
| `AWS_DEFAULT_REGION` | AWS region fallback | `ap-southeast-1` |
| `SSL_MODE` | SSL certificate mode | `letsencrypt` |
| `DEV_MODE` | Development mode | `false` |

### Quick Setup Commands
```bash
# 1. Clone and configure
git clone https://github.com/your-username/ankicommunity-sync-server.git
cd ankicommunity-sync-server

# 2. Setup environment (REQUIRED)
cp .env.example .env
nano .env  # Add your AWS/Cognito credentials

# 3. Deploy
docker-compose -f docker-compose.latest.yml up -d

# 4. Verify
docker ps  # Should show both containers running
curl -k https://localhost/sync/hostKey  # Test endpoint
```

---

## Architecture Overview

### Production Architecture (nginx-based)
```
[Anki Client] â†’ [Port 443/HTTPS] â†’ [nginx Reverse Proxy] â†’ [Port 27702/HTTP] â†’ [Sync Server] â†’ [AWS Cognito]
                                           â†“ SSL Termination
                                    [anki-nginx-proxy]         [anki-sync-server-nginx]
```

### nginx HTTPS Implementation

**nginx Reverse Proxy** (`Dockerfile.nginx`):
- **Technology**: Production-grade nginx with Alpine Linux
- **SSL Management**: Automatic Let's Encrypt certificates via certbot
- **Features**:
  - HTTP/2 enabled for performance
  - Strong SSL cipher suites (TLS 1.2/1.3)
  - Security headers (HSTS, X-Frame-Options, etc.)
  - Large file uploads (2GB max for collections)
  - Real-time proxy (buffering disabled)

**Why nginx**:
- âœ… **Production proven** - battle-tested reverse proxy
- âœ… **Performance** - efficient handling of HTTPS/HTTP/2
- âœ… **SSL automation** - integrated Let's Encrypt support
- âœ… **Security** - comprehensive security headers and configurations
- âœ… **Monitoring** - detailed access/error logs

**Certificate Management**:
```bash
# Automatic Let's Encrypt certificates
./scripts/setup-https-certs.sh letsencrypt

# Self-signed fallback for development
./scripts/setup-https-certs.sh self-signed

# Certificate info
./scripts/setup-https-certs.sh info
```

**AWS Cognito Integration**:
- Collection folders: `/data/collections/{cognito_username}/`
- Session caching reduces API calls  
- Supports multiple auth flows (`USER_PASSWORD_AUTH`, `ADMIN_NO_SRP_AUTH`)

---

## ðŸ” AWS Cognito Authentication

### Prerequisites
1. **AWS Account** with IAM access key and secret
2. **Cognito User Pool** with App Client configured
3. **Environment variables** configured in `.env` file

### AWS Setup
```bash
# Get your Cognito configuration from AWS Console:
# 1. Go to Amazon Cognito â†’ User pools
# 2. Select your user pool
# 3. Note the User pool ID
# 4. Go to App integration â†’ App clients
# 5. Note Client ID and Client secret

# Add to your .env file:
ANKISYNCD_COGNITO_USER_POOL_ID=your_user_pool_id
ANKISYNCD_COGNITO_CLIENT_ID=your_client_id  
ANKISYNCD_COGNITO_CLIENT_SECRET=your_client_secret
```

### Collection Directory Structure
When users authenticate, collections are automatically organized by Cognito username:
```
/data/collections/
â”œâ”€â”€ john.doe/           # Cognito username (not email)
â”‚   â”œâ”€â”€ collection.anki2
â”‚   â””â”€â”€ collection.media/
â””â”€â”€ jane.smith/
    â”œâ”€â”€ collection.anki2
    â””â”€â”€ collection.media/
```

---

## ðŸ³ Docker Deployment

### nginx-based Production Setup (Recommended)
**Image Size**: Optimized production setup

```bash
# 1. Configure environment variables (REQUIRED)
cp .env.example .env
nano .env  # Add your AWS credentials and Cognito settings

# 2. Deploy with secure configuration
docker-compose -f docker-compose.latest.yml up -d

# 3. Verify services are running
docker-compose -f docker-compose.latest.yml ps
# Should show:
# - anki-nginx-proxy (ports 80:80, 443:443)  
# - anki-sync-server (internal port 27702)
```

### Security Features
- **Environment Variables**: All credentials use secure env vars (never committed)
- **Non-root Containers**: Enhanced security with dedicated user accounts
- **SSL/TLS**: Production-grade HTTPS with nginx reverse proxy

### Essential Commands

```bash
# Production deployment with nginx + SSL
docker-compose -f docker-compose.latest.yml up -d

# View logs
docker-compose -f docker-compose.latest.yml logs -f nginx
docker-compose -f docker-compose.latest.yml logs -f anki-sync-server

# Monitor sync activity
docker logs anki-sync-server-nginx 2>&1 | grep -E "(Authentication|SUCCESS|ERROR)"

# nginx access logs (sync requests)
docker exec anki-nginx-proxy tail -f /var/log/nginx/access.log

# Container shell access
docker exec -it anki-sync-server-nginx bash

# Stop services
docker-compose -f docker-compose.latest.yml down
```

### Volume Mounts (Critical for Data Persistence)
```yaml
volumes:
  # Collections storage - MUST persist across restarts
  - ./data:/data
  
  # Let's Encrypt SSL certificates
  - ./letsencrypt:/etc/letsencrypt:rw
  
  # Web root for ACME challenge
  - ./certbot-www:/var/www/certbot:rw
  
  # nginx logs
  - ./logs/nginx:/var/log/nginx
```

### Container Architecture
```
anki-nginx-proxy        (ports 80:80, 443:443)
    â†“ nginx reverse proxy â†“
anki-sync-server-nginx  (internal port 27702)
    â†“ authenticates via â†“  
AWS Cognito User Pool
    â†“ stores collections in â†“
./data/collections/{cognito_username}/
```

---

## ðŸ”§ Scripts and Deployment Automation

The project includes several deployment and management scripts:

### Available Scripts
- **`scripts/aws-deploy.sh`** - Full AWS deployment with SSL certificates
- **`scripts/docker-deploy.sh`** - Production deployment with registry management
- **`scripts/docker-dev.sh`** - Development environment management
- **`scripts/generate-nginx-config.sh`** - Dynamic nginx configuration generation
- **`scripts/setup-https-certs.sh`** - SSL certificate management (Let's Encrypt, self-signed, custom)

### Usage Examples
```bash
# Generate SSL certificates
./scripts/setup-https-certs.sh letsencrypt
./scripts/setup-https-certs.sh self-signed

# Development environment
./scripts/docker-dev.sh build
./scripts/docker-dev.sh up

# Production deployment
./scripts/docker-deploy.sh production latest
```

---

## ðŸ› Troubleshooting & Debugging

### Modern Anki Client Compatibility (v25.02+)

**Key Fixes Implemented:**

#### 1. Authentication Flow Issues
- **Issue**: Client discovery requests weren't triggering authentication dialogs
- **Fix**: Return HTTP 400 "expected auth" for discovery requests (`{"k": ""}` with empty body)

#### 2. Missing anki-original-size Header
- **Issue**: All zstd-compressed responses must include `anki-original-size` header with uncompressed byte count
- **Fix**: Updated response handling to include proper size headers

#### 3. Request Body Parsing for Streaming Clients
- **Issue**: Modern clients stream request bodies without `Content-Length` headers using chunked transfer encoding
- **Fix**: Enhanced request parsing to handle chunked transfer encoding and missing content-length headers

#### 4. Media USN Synchronization (303 Error Fix)
- **Issue**: Server's media USN didn't match client expectations, causing 303 stream failure errors
- **Root Cause**: Legacy media manager and modern media manager had inconsistent USN values
- **Fix**: Unified all media sync operations to use the modern media manager (`media_manager.py`) with atomic USN tracking
- **Result**: Server USN now precisely reflects the number of media operations, matching client expectations

#### 5. Media Sync Compression for Modern Clients (v11+ Protocol)
- **Issue**: Modern Anki clients (sync protocol v11+) expect media ZIP files to be zstd-compressed but server returned raw ZIP data
- **Root Cause**: Server's `downloadFiles` operation wasn't compressing media payload for clients that advertise sync version â‰¥ 11
- **Symptoms**: Second client could receive collection data but media downloads would fail during decompression
- **Fix**: Implemented version-aware compression - zstd compress media ZIP for v11+ clients, raw ZIP for legacy clients
- **Technical Details**: 
  - Modern clients send `anki-sync: {"v":11,...}` header and expect zstd-compressed body with `anki-original-size` header
  - Server now checks `req.get_sync_version() >= 11` and applies `zstd.ZstdCompressor().compress()` accordingly
  - Maintains backward compatibility for older clients that expect uncompressed ZIP files
- **Result**: Media sync now works correctly for all modern Anki clients while preserving legacy client support

#### 6. JSON Field Type Compatibility (Critical Protocol Fix)
- **Issue**: JsonError with "invalid type: integer X, expected a string" or "invalid type: string X, expected i64"
- **Root Cause**: Anki's sync protocol has specific requirements for field serialization that differ from database storage types
- **Symptoms**: 
  - Client receives `JsonError { info: "invalid type: integer 1090421990, expected a string" }` 
  - Sync fails after successful authentication but before data transfer completes
- **Fix**: Implemented field-specific type conversion in sync responses:
  - **Table dumps (chunk data)**: Most fields remain as integers (IDs, timestamps, USN)
  - **Graves (deletion records)**: Object IDs must be strings for cross-platform compatibility
  - **Checksum fields**: `csum` field converted to string due to JavaScript 53-bit integer precision limits
- **Technical Details**:
  ```python
  # Example: notes table csum field conversion
  if field_name == 'csum' and isinstance(value, int):
      converted_value = str(value)  # "1090421990" instead of 1090421990
  ```
- **Protocol Rules Discovered**:
  - **Graves**: All object IDs (oid) serialized as strings
  - **Chunk data**: IDs stay as integers, but csum becomes string
  - **Timestamps**: Always integers (mod, due, usn, etc.)
- **Result**: Eliminates JSON deserialization errors and enables successful sync for modern Anki clients

### Common Error Patterns & Solutions

| Error | Cause | Solution |
|-------|-------|----------|
| `Exception: expected auth` | Discovery request not returning HTTP 400 | Update authentication flow in `sync_app.py` |
| `missing original_size` | Missing `anki-original-size` header | Ensure all responses return proper size headers |
| `Authentication failed` | User not in Cognito | Verify AWS Cognito configuration |
| `SSL certificate error` | Self-signed certificate rejected | Use Let's Encrypt or add cert to trust store |
| `NoneType object has no attribute 'scalar'` | Collection database corrupted/missing | Server auto-recovers with schema fallback; client uploads restore collection |
| Server reports "no collections" but has media | Database inconsistency after crash | Normal - media databases survive restarts; collection upload restores sync |
| Quick sync with thousands of media files | Efficient differential sync working correctly | Expected behavior - only transfers changed files (USN-based) |
| `303 stream failure` during media sync | Media USN mismatch between client/server | Fixed: Modern media manager ensures precise USN tracking |

### Quick Recovery Commands
```bash
# Stop everything and rebuild
docker-compose -f docker-compose.latest.yml down
docker-compose -f docker-compose.latest.yml up --build -d

# Check container status
docker ps
docker logs anki-sync-server-nginx --tail 10
docker logs anki-nginx-proxy --tail 10

# Test connectivity
curl -k https://localhost/sync/hostKey
```

---

## Extending & Customization

### Authentication Backends
The current implementation uses AWS Cognito (`cognito_manager.py`), but the architecture supports:
* **Custom OAuth providers** - implement new manager in `users/`
* **LDAP integration** - extend base authentication manager
* **Multi-tenant auth** - add organization-based user isolation

### Monitoring Integration
* **Prometheus metrics** - wrap ASGI app with metrics middleware
* **Logging enhancements** - structured logging for sync operations
* **Health checks** - extend container health monitoring

### Storage Customization
* **S3 media storage** - replace local filesystem in `media_manager.py`
* **Database clustering** - distribute collections across multiple nodes
* **Backup automation** - implement automated collection backups

### Performance Optimization
* **Redis session caching** - replace in-memory Cognito session cache
* **CDN integration** - serve media files through CDN
* **Load balancing** - scale sync servers horizontally

---

## Project Status & Reliability

**âœ… PRODUCTION READY & BATTLE-TESTED**
- Secure AWS Cognito authentication with session caching
- Modern Anki client compatibility (v25.02+) with full protocol compliance  
- Docker deployment with nginx HTTPS termination and Let's Encrypt automation
- Crash-resilient architecture with separated collection/media storage
- Differential media sync handles thousands of files efficiently
- Robust schema compatibility across Anki versions 11-18
- Comprehensive error recovery and database integrity protection

**ðŸ”§ CONFIGURATION REQUIRED**
- AWS Cognito User Pool setup with proper IAM permissions
- Domain name registration and DNS configuration
- Docker Compose environment variables (.env file setup)
- SSL certificate management (automated via Let's Encrypt)

**ðŸ§  SANITY PRESERVATION METHOD**
To maintain clarity while implementing complex sync protocols and crash recovery mechanisms, this codebase follows a principle of **"explain the why, not just the what"** in both logging and documentation. Every non-trivial operation includes context about what problem it solves, particularly around edge cases like orphaned media databases, schema detection failures, and differential sync optimizations. The extensive logging helps trace exactly what happened during sync issues, making debugging straightforward rather than archeological.

---

## License
Released under the **GNU AGPL-v3+**.  
Copyright Â© the respective contributors.